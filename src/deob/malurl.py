from datetime import datetime
import commands
import psycopg2
import hashlib
import locale
import gzip
import time
import sys
import re
import os

def downloadURL():
	'''
	cp data from urlcrawl machine and unzip those files.
	'''
	cmdrsync = 'rsync -avz urlcrawl:/space/malicious-urls/ /home/intern/chromium/webcrawl-malware/src/data/MALURLs/'
	# cmdcp = 'cp /space/malicious-urls/ ../../data/TempData/MALURLs/'
	cmdunzip = 'gunzip -k -f --suffix .gzip ../../data/TempData/MALURLs/*.gzip'
	# print cmdrsync + '\n' + cmdunzip
	print cmdrsync + '\n' + cmdunzip
	print commands.getoutput(cmdrsync + '; ' + cmdunzip)


def containsAnyStr(tosearch, strlist):
	for s in strlist:
		if s in tosearch:
			return True
	return False


def formatToURL(infile, outfile, thedate, allhash, alltype):
	print infile
	print outfile

	# set input and output
	inf = gzip.open(infile, 'rb')
	inf = inf.read().split('\n')
	outf = open(outfile, 'w')

	# the malicious type of urls focus
	type_to_focus = ['Blacole', 'Exploit', 'Obfuscator', 'JS', 'Malicious']

	for line in inf:
		line = line.split(',')
		if len(line) != 6:
			continue
		link = line[0]
		domain = line[2]
		real_type = line[4]
		
		'''
		If the real_type is already mapped, assign the label directly
		Else if the real_type is what we want, map it and assign label
		'''
		if real_type in alltype:
			None
		elif containsAnyStr(real_type, type_to_focus):
			# real_type, M1
			alltype[real_type] = 'M' + str(len(alltype) + 1)
		else:
			continue

		label = alltype[real_type]
		hexhash = hashlib.sha256(link).hexdigest()
		# Avoid duplicate keys
		if hexhash in allhash:
			continue
		else:
			allhash[hexhash] = True
		# Format for psql input
		outf.write(hexhash + ',' + link + ',' + domain + ',' + label + ',' + real_type + ',' + thedate + '\n')



def malurl(allhash, alltype, basedir):
	locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' )

	# downloadURL()
	malurldir = "/space/malicious-urls/"
	cmdlsinput = 'ls ' + malurldir + 'www.malwareurl.com-*'
	inputfiles = commands.getoutput(cmdlsinput).split('\n')

	for inputfile in inputfiles:
		try:
			date = inputfile.split('/')[-1].split('-')[1:]
			date[2] = date[2].split('.')[0]		# get rid of the .gzip suffix
			date = datetime(int(date[0]), int(date[1]), int(date[2]))
		except:
			print 'Error: bad filename', inputfile
			continue
		thedate = date.strftime('%Y-%m-%d')
		outputfile = basedir + 'URLs/malurl-' + thedate
		if not os.path.exists(outputfile):
			print thedate
			formatToURL(inputfile, outputfile, thedate, allhash, alltype)


def loadstate(allhash, alltype, basedir):
	# load the available hash from file
	infile = basedir + 'allhash'
	if os.path.exists(infile):
		infile = open(infile, 'r')
		for line in infile:
			allhash[line] = True

	# load the available types from file
	infile = basedir + 'alltype'
	if os.path.exists(infile):
		infile = open(infile, 'r')
		for line in infile:
			line = line.split(',')
			real_type = line[0]
			label = line[1]
			alltype[real_type] = label


def savestate(allhash, alltype, basedir):
	# save the available hash to file
	outfile = basedir + 'allhash'
	outfile = open(outfile, 'w')
	for key in allhash:
		outfile.write(key + '\n')
	# save the available types to file
	outfile = basedir + 'alltype'
	outfile = open(outfile, 'w')
	for key, value in alltype.items():
		outfile.write(key + ',' + value + '\n')


def main():
	basedir = '../../data/TempData/'
	allhash = dict()
	alltype = dict()
	loadstate(allhash, alltype, basedir)
	while True:
		malurl(allhash, alltype, basedir)
		savestate(allhash, alltype, basedir)
		print 'Sleeping'
		time.sleep(60 * 60 * 24)


if __name__=="__main__":
	main()
